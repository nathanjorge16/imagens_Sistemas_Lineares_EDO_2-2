# üìñ Guia de Migra√ß√£o - Do df.to_sql() para CsvToDatabaseLoader

Este guia mostra como migrar do c√≥digo simples usando `df.to_sql()` para o sistema profissional de ingest√£o.

---

## ‚ùå C√≥digo Antigo (Exemplo que voc√™ usava)

```python
from sqlalchemy import text

# Limpar tabela (opcional)
# with engine.begin() as conn:
#     conn.execute(text("TRUNCATE TABLE matriz_cargas_codemge.id_matriz_duto_comprimento_uf"))

# Enviar DataFrame para o banco
df_limites_final.to_sql(
    name="jenks_produtos",
    schema="amb_rotas",
    con=conn,
    if_exists="replace",
    index=False
)

print("‚úÖ Dados inseridos com sucesso!")
```

### ‚ö†Ô∏è Problemas com essa abordagem:
1. ‚ùå **Sem valida√ß√£o de tipos** - Dados inv√°lidos passam direto
2. ‚ùå **Sem logging estruturado** - Dif√≠cil debugar problemas
3. ‚ùå **Sem controle de erros** - Falha completa ou sucesso completo
4. ‚ùå **Sem an√°lise pr√©via** - N√£o sabe o que vai inserir
5. ‚ùå **Sem DDL sugerido** - Tem que criar tabela manualmente
6. ‚ùå **Sem deduplica√ß√£o** - Duplicatas passam direto
7. ‚ùå **Sem dry-run** - Testa direto em produ√ß√£o
8. ‚ùå **Sem relat√≥rios** - N√£o sabe quantas linhas falharam

---

## ‚úÖ C√≥digo Novo (Sistema Profissional)

### Migra√ß√£o 1: B√°sica (equivalente ao antigo)

```python
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

# Criar engine (se ainda n√£o tem)
engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

# Criar loader
loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/jenks_produtos.csv",  # Caminho do CSV
    schema="amb_rotas",
    table_name="jenks_produtos",
    if_exists="replace",  # Mesmo comportamento do antigo
    chunk_size=10000,
)

# Executar
report = loader.run(dry_run=False)
print(f"‚úÖ {report.rows_inserted} linhas inseridas com sucesso!")
```

**Ganhos imediatos**:
- ‚úÖ Valida√ß√£o de tipos
- ‚úÖ Logging estruturado
- ‚úÖ Relat√≥rio detalhado
- ‚úÖ Inser√ß√£o em chunks

---

### Migra√ß√£o 2: Com Dry-Run (recomendado)

```python
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/jenks_produtos.csv",
    schema="amb_rotas",
    table_name="jenks_produtos",
    if_exists="replace",
)

# 1. Primeiro, dry-run para an√°lise
print("üìä Analisando dados...")
loader.run(dry_run=True)

# 2. Depois, inser√ß√£o real
input("Pressione ENTER para inserir...")
report = loader.run(dry_run=False)
```

**Ganhos adicionais**:
- ‚úÖ Verifica dados antes de inserir
- ‚úÖ V√™ DDL sugerido
- ‚úÖ Identifica problemas cedo

---

### Migra√ß√£o 3: Com Valida√ß√£o e Coleta de Erros

```python
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/jenks_produtos.csv",
    schema="amb_rotas",
    table_name="jenks_produtos",
    if_exists="replace",
    validate_types=True,  # ‚Üê Valida tipos
    error_strategy="collect_errors",  # ‚Üê Coleta erros em vez de falhar
)

report = loader.run(dry_run=False)

# Verifica se houve erros
if report.validation_result and not report.validation_result.is_valid:
    print(f"‚ö†Ô∏è {report.validation_result.invalid_rows_count} linhas inv√°lidas")
    print(f"‚úÖ {report.rows_inserted} linhas v√°lidas inseridas")
    print(f"üìÑ Linhas inv√°lidas salvas em: jenks_produtos_invalid_rows.csv")
else:
    print(f"‚úÖ Todas as {report.rows_inserted} linhas inseridas!")
```

**Ganhos adicionais**:
- ‚úÖ Insere linhas v√°lidas mesmo com erros
- ‚úÖ Salva linhas inv√°lidas para an√°lise
- ‚úÖ Relat√≥rio de erros detalhado

---

### Migra√ß√£o 4: Com Cria√ß√£o Autom√°tica de Tabela

```python
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/novos_dados.csv",
    schema="analytics",
    table_name="dados_novos",
    if_exists="fail",  # Falha se j√° existir
    create_table=True,  # ‚Üê Cria automaticamente!
)

# Ver DDL que ser√° criado
ddl = loader.suggest_sql_schema()
print("DDL que ser√° executado:")
print(ddl)

# Confirmar e executar
input("OK? Pressione ENTER...")
report = loader.run(dry_run=False)
```

**Ganhos adicionais**:
- ‚úÖ N√£o precisa criar tabela manualmente
- ‚úÖ DDL otimizado automaticamente
- ‚úÖ Tipos SQL adequados

---

### Migra√ß√£o 5: Com Deduplica√ß√£o

```python
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/clientes.csv",
    schema="crm",
    table_name="clientes",
    if_exists="append",
    dedup_columns=["cpf", "email"],  # ‚Üê Remove duplicatas
)

report = loader.run(dry_run=False)
print(f"‚úÖ {report.rows_inserted} linhas √∫nicas inseridas!")
```

**Ganhos adicionais**:
- ‚úÖ Remove duplicatas automaticamente
- ‚úÖ Mant√©m primeiro registro

---

## üîÑ Tabela de Equival√™ncia

| Recurso | C√≥digo Antigo | C√≥digo Novo |
|---------|---------------|-------------|
| Ler CSV | `pd.read_csv()` + `to_sql()` | `CsvToDatabaseLoader(csv_path=...)` |
| Inserir | `to_sql()` | `loader.run()` |
| Replace | `if_exists="replace"` | `if_exists="replace"` |
| Append | `if_exists="append"` | `if_exists="append"` |
| Truncate | `TRUNCATE TABLE` manual | Autom√°tico com `if_exists="replace"` |
| Valida√ß√£o | ‚ùå N√£o tinha | ‚úÖ `validate_types=True` |
| Dry-run | ‚ùå N√£o tinha | ‚úÖ `run(dry_run=True)` |
| Erros | ‚ùå Falha tudo | ‚úÖ `error_strategy="collect_errors"` |
| Logging | `print()` manual | ‚úÖ Logging estruturado |
| Relat√≥rio | ‚ùå N√£o tinha | ‚úÖ `IngestionReport` |
| DDL | ‚ùå Manual | ‚úÖ `suggest_sql_schema()` |
| Dedup | ‚ùå Manual | ‚úÖ `dedup_columns=[...]` |

---

## üìã Checklist de Migra√ß√£o

### Antes de migrar:
- [ ] Instalar depend√™ncias: `pip install -r requirements.txt`
- [ ] Fazer backup do banco de dados
- [ ] Testar em ambiente de desenvolvimento primeiro

### Durante a migra√ß√£o:
- [ ] Identificar todos os `df.to_sql()` no c√≥digo
- [ ] Substituir por `CsvToDatabaseLoader`
- [ ] Adicionar dry-run antes de cada inser√ß√£o
- [ ] Configurar valida√ß√£o de tipos
- [ ] Configurar estrat√©gia de erros

### Depois da migra√ß√£o:
- [ ] Testar com dados de produ√ß√£o (dry-run)
- [ ] Verificar logs gerados
- [ ] Analisar relat√≥rios
- [ ] Monitorar performance
- [ ] Documentar mudan√ßas

---

## üéØ Exemplo Real: Caso de Uso Completo

### ANTES (seu c√≥digo):
```python
# C√≥digo antigo - matriz_cargas_codemge
from sqlalchemy import text

with engine.begin() as conn:
    # Opcional: limpar antes
    conn.execute(text("TRUNCATE TABLE matriz_cargas_codemge.id_matriz_duto_comprimento_uf"))
    
    # Inserir
    df_limites_final.to_sql(
        name="id_matriz_duto_comprimento_uf",
        schema="matriz_cargas_codemge",
        con=conn,
        if_exists="append",
        index=False
    )

print("‚úÖ Dados inseridos!")
```

### DEPOIS (sistema profissional):
```python
# C√≥digo novo - matriz_cargas_codemge
from sqlalchemy import create_engine
from csv_ingestion import CsvToDatabaseLoader

engine = create_engine("postgresql+psycopg2://usuario:senha@host:porta/banco")

loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/matriz_cargas.csv",  # Salve o DataFrame como CSV antes
    schema="matriz_cargas_codemge",
    table_name="id_matriz_duto_comprimento_uf",
    if_exists="replace",  # Trunca + insere (equivalente ao TRUNCATE + append)
    chunk_size=10000,
    validate_types=True,
    error_strategy="collect_errors",
)

# Dry-run primeiro
print("üìä An√°lise pr√©via:")
loader.run(dry_run=True)

# Confirmar
input("Continuar com inser√ß√£o? ENTER...")

# Inserir
report = loader.run(dry_run=False)

# Resultado
print(f"""
‚úÖ INGEST√ÉO CONCLU√çDA!
   Tabela: {report.schema}.{report.table_name}
   Linhas CSV: {report.total_rows_csv}
   Linhas inseridas: {report.rows_inserted}
   Dura√ß√£o: {report.duration_seconds:.2f}s
""")
```

---

## üí° Dicas Importantes

### 1. Salvar DataFrame como CSV
Se voc√™ j√° tem um DataFrame em mem√≥ria:
```python
# Salvar DataFrame como CSV
df_limites_final.to_csv("data/matriz_cargas.csv", index=False)

# Depois usar o loader
loader = CsvToDatabaseLoader(
    engine=engine,
    csv_path="data/matriz_cargas.csv",
    ...
)
```

### 2. Usar o mesmo `engine`
Voc√™ pode reutilizar o mesmo engine:
```python
# Engine que voc√™ j√° usa
engine = create_engine("postgresql+psycopg2://...")

# Usar no loader
loader = CsvToDatabaseLoader(engine=engine, ...)
```

### 3. Manter compatibilidade
Se quiser manter o c√≥digo antigo funcionando:
```python
# Op√ß√£o 1: C√≥digo antigo
df.to_sql(...)

# Op√ß√£o 2: Novo sistema (gradualmente)
loader = CsvToDatabaseLoader(...)
loader.run()
```

---

## üöÄ Pr√≥ximos Passos

1. **Teste o quick_start.py**: 
   ```bash
   python quick_start.py
   ```

2. **Rode os exemplos**:
   ```bash
   python examples/exemplo_01_basico.py
   ```

3. **Teste via CLI**:
   ```bash
   python cli.py --csv data/exemplo_produtos.csv --db sqlite:///test.db --schema main --table produtos --dry-run
   ```

4. **Migre gradualmente**: Comece com uma tabela, depois expanda

---

## ‚ùì FAQ

**P: Preciso mudar meu banco de dados?**
R: N√£o! O sistema funciona com qualquer banco suportado pelo SQLAlchemy (Postgres, MySQL, SQLite, etc).

**P: Posso usar com DataFrames que j√° est√£o em mem√≥ria?**
R: Sim! Basta salvar como CSV primeiro: `df.to_csv("temp.csv", index=False)`

**P: √â muito mais lento que o c√≥digo antigo?**
R: N√£o significativamente. A valida√ß√£o adiciona ~5-10% de overhead, mas evita erros.

**P: Posso desabilitar a valida√ß√£o?**
R: Sim: `validate_types=False`

**P: Funciona com CSVs grandes (> 1GB)?**
R: Sim! A inser√ß√£o em chunks previne memory overflow.

---

‚úÖ **Migra√ß√£o conclu√≠da com sucesso!**
