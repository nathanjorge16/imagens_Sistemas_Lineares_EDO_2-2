# ğŸ—ï¸ Arquitetura do Sistema de IngestÃ£o

## VisÃ£o Geral

Este documento descreve a arquitetura do sistema profissional de ingestÃ£o de CSV em banco de dados.

---

## ğŸ¯ Objetivos de Design

1. **Robustez**: Zero erros em produÃ§Ã£o atravÃ©s de validaÃ§Ã£o extensiva
2. **Modularidade**: Componentes independentes e testÃ¡veis
3. **Extensibilidade**: FÃ¡cil adicionar novos tipos e validadores
4. **Observabilidade**: Logging e relatÃ³rios detalhados
5. **Usabilidade**: API simples e intuitiva

---

## ğŸ“¦ Componentes Principais

### 1. **Models** (`models.py`)
Define estruturas de dados usando `dataclasses`:
- `IngestionConfig`: ConfiguraÃ§Ã£o da ingestÃ£o
- `ColumnAnalysis`: AnÃ¡lise de uma coluna
- `ValidationError`: Erro de validaÃ§Ã£o
- `ValidationResult`: Resultado da validaÃ§Ã£o
- `IngestionReport`: RelatÃ³rio completo

**Responsabilidades**:
- Estruturar dados
- ValidaÃ§Ã£o bÃ¡sica de tipos
- ConversÃ£o para dict/JSON

### 2. **Type Inference** (`type_inference.py`)
InferÃªncia inteligente de tipos Pandas â†’ SQL.

**Classes**:
- `TypeInference`: Classe principal com mÃ©todos estÃ¡ticos

**Funcionalidades**:
- Mapeamento Pandas â†’ SQL
- AnÃ¡lise estatÃ­stica de colunas
- GeraÃ§Ã£o de DDL
- OtimizaÃ§Ã£o de tipos (ex: SMALLINT vs INTEGER vs BIGINT)

**Algoritmo de InferÃªncia**:
```
1. Detectar dtype do Pandas
2. Se object â†’ tentar converter para numÃ©rico/datetime/boolean
3. Se numÃ©rico â†’ otimizar tipo baseado em range
4. Se string â†’ calcular tamanho e sugerir VARCHAR ou TEXT
5. Retornar tipo SQL otimizado
```

### 3. **Validators** (`validators.py`)
ValidaÃ§Ã£o de dados antes da inserÃ§Ã£o.

**Classes**:
- `DataValidator`: Validador principal

**EstratÃ©gias**:
- `fail_fast`: Para no primeiro erro
- `collect_errors`: Coleta todos os erros

**ValidaÃ§Ãµes por Tipo**:
- Integer: ConversÃ£o + range check
- Float: ConversÃ£o numÃ©rica
- Boolean: Valores vÃ¡lidos
- Timestamp: ConversÃ£o datetime
- String: Tamanho mÃ¡ximo (VARCHAR)

### 4. **Loader** (`loader.py`)
Classe principal orquestradora.

**Classe**: `CsvToDatabaseLoader`

**Pipeline de ExecuÃ§Ã£o**:
```
run() â†’ 
  â”œâ”€ 1. _read_csv()
  â”œâ”€ 2. _analyze_csv()
  â”œâ”€ 3. _generate_ddl()
  â”œâ”€ 4. _check_table_exists()
  â”‚    â”œâ”€ Se existe â†’ _validate_against_db_schema()
  â”‚    â””â”€ Se nÃ£o existe â†’ _create_table() (se configurado)
  â”œâ”€ 5. _validate_data() (se habilitado)
  â”œâ”€ 6. _deduplicate() (se configurado)
  â””â”€ 7. _insert_data() (se nÃ£o dry-run)
```

**Responsabilidades**:
- OrquestraÃ§Ã£o do pipeline
- Logging estruturado
- Controle de transaÃ§Ãµes
- GeraÃ§Ã£o de relatÃ³rios

### 5. **Utils** (`utils.py`)
FunÃ§Ãµes utilitÃ¡rias.

**FunÃ§Ãµes**:
- `setup_logger()`: ConfiguraÃ§Ã£o de logging
- `print_report()`: ImpressÃ£o formatada
- `print_column_analysis()`: Tabela de anÃ¡lise
- `save_report_to_file()`: Salvar em JSON
- `format_duration()`: FormataÃ§Ã£o de tempo

### 6. **CLI** (`cli.py`)
Interface de linha de comando.

**Funcionalidades**:
- Parsing de argumentos
- ValidaÃ§Ã£o de parÃ¢metros
- Tratamento de exceÃ§Ãµes
- Help text detalhado

---

## ğŸ”„ Fluxo de Dados

```
CSV File
   â†“
[Leitura] â†’ Pandas DataFrame
   â†“
[AnÃ¡lise] â†’ ColumnAnalysis (para cada coluna)
   â†“
[InferÃªncia] â†’ Tipos SQL sugeridos
   â†“
[DDL] â†’ CREATE TABLE statement
   â†“
[ValidaÃ§Ã£o] â†’ ValidationResult + DataFrame vÃ¡lido/invÃ¡lido
   â†“
[DeduplicaÃ§Ã£o] â†’ DataFrame Ãºnico
   â†“
[InserÃ§Ã£o em Chunks] â†’ Database
   â†“
[RelatÃ³rio] â†’ IngestionReport
```

---

## ğŸ§© PadrÃµes de Design

### 1. **Strategy Pattern**
Usado para estratÃ©gias de erro:
```python
ErrorStrategy.FAIL_FAST
ErrorStrategy.COLLECT_ERRORS
```

### 2. **Factory Pattern**
CriaÃ§Ã£o de anÃ¡lises de colunas:
```python
TypeInference.analyze_column(series, name)
```

### 3. **Builder Pattern**
ConfiguraÃ§Ã£o do loader:
```python
CsvToDatabaseLoader(
    engine=engine,
    csv_path=path,
    ...
)
```

### 4. **Template Method**
Pipeline de execuÃ§Ã£o no `run()`:
```python
def run(self, dry_run):
    self._read_csv()
    self._analyze_csv()
    ...
```

---

## ğŸ”Œ Pontos de ExtensÃ£o

### Adicionar novo tipo SQL
Em `type_inference.py`:
```python
PANDAS_TO_SQL_MAPPING = {
    "novo_tipo_pandas": "NOVO_TIPO_SQL",
    ...
}
```

### Adicionar nova validaÃ§Ã£o
Em `validators.py`:
```python
@classmethod
def _validate_novo_tipo(cls, series, column_name, sql_type):
    # Implementar validaÃ§Ã£o
    return errors
```

### Adicionar novo database
Driver especÃ­fico em `requirements.txt`:
```txt
# Oracle
cx_Oracle>=8.0.0
```

---

## ğŸ“Š Diagrama de Classes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CsvToDatabaseLoader â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€usesâ”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚           â”‚TypeInference â”‚
           â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€usesâ”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚           â”‚DataValidator â”‚
           â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â””â”€â”€â”€usesâ”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Models (dataclass)â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Performance

### OtimizaÃ§Ãµes Implementadas
1. **Chunked Insertion**: Evita memory overflow
2. **Type Optimization**: Usa tipos menores quando possÃ­vel
3. **Lazy Validation**: SÃ³ valida se configurado
4. **Batch Operations**: SQLAlchemy method='multi'

### Benchmarks Esperados
- **10k rows**: ~1-2 segundos
- **100k rows**: ~10-15 segundos
- **1M rows**: ~90-120 segundos

(Varia conforme hardware e latÃªncia de rede)

---

## ğŸ”’ SeguranÃ§a

### PrÃ¡ticas Implementadas
1. **Prepared Statements**: SQLAlchemy protege contra SQL injection
2. **Validation**: Todos os dados validados antes de inserÃ§Ã£o
3. **Transaction Control**: Rollback automÃ¡tico em caso de erro
4. **Schema Validation**: Verifica compatibilidade com tabela existente

---

## ğŸ“ Logging

### NÃ­veis de Log
- `INFO`: Progresso normal (padrÃ£o)
- `WARNING`: Avisos nÃ£o-crÃ­ticos
- `ERROR`: Erros de execuÃ§Ã£o
- `DEBUG`: InformaÃ§Ãµes detalhadas (desenvolvimento)

### Estrutura de Log
```
YYYY-MM-DD HH:MM:SS | module | LEVEL | message
```

---

## ğŸ§ª Testabilidade

### EstratÃ©gia de Testes
1. **Unit Tests**: Cada componente isolado
2. **Integration Tests**: Pipeline completo
3. **Fixtures**: SQLite em memÃ³ria para testes

### Cobertura Alvo
- MÃ­nimo: 80%
- Ideal: 90%+

---

## ğŸ”® Melhorias Futuras

1. **Parallel Loading**: InserÃ§Ã£o paralela para grandes volumes
2. **UPSERT Support**: INSERT ... ON CONFLICT
3. **Primary Key Detection**: DetecÃ§Ã£o automÃ¡tica de PKs
4. **Schema Evolution**: Detectar mudanÃ§as e sugerir ALTER TABLE
5. **Cloud Storage**: Suporte a S3, GCS, Azure Blob
6. **Streaming**: Processamento de CSVs maiores que memÃ³ria
7. **Compression**: Suporte a CSV.gz, CSV.zip
8. **Multi-file**: IngestÃ£o de mÃºltiplos CSVs em batch

---

## ğŸ“š ReferÃªncias

- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [PostgreSQL Data Types](https://www.postgresql.org/docs/current/datatype.html)
- [Clean Architecture Principles](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)

---

**Ãšltima atualizaÃ§Ã£o**: 2024-11-26
